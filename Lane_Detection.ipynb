{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 362\u001b[0m\n\u001b[0;32m    359\u001b[0m lane_image\u001b[38;5;241m=\u001b[39m process_frame(frame)\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# detecting the cars\u001b[39;00m\n\u001b[1;32m--> 362\u001b[0m model_frame\u001b[38;5;241m=\u001b[39m\u001b[43mcar_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlane_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_per_pixel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m out\u001b[38;5;241m.\u001b[39mwrite(model_frame)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m# showing the output in real time while its saving \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 257\u001b[0m, in \u001b[0;36mcar_detection\u001b[1;34m(frame, prev_centers, distance_per_pixel)\u001b[0m\n\u001b[0;32m    255\u001b[0m score \u001b[38;5;241m=\u001b[39m obj_data[\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m    256\u001b[0m prob \u001b[38;5;241m=\u001b[39m obj_data[\u001b[38;5;241m5\u001b[39m:]\n\u001b[1;32m--> 257\u001b[0m detected_class \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m#if the detected class is the car and its score is greater than 0.5 then we will consider it to be a car\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_class \u001b[38;5;241m==\u001b[39m car_label_index \u001b[38;5;129;01mand\u001b[39;00m score \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:1298\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "#loading yolo model for object detection \n",
    "net = cv2.dnn.readNetFromDarknet(\"yolov3.cfg\", \"yolov3.weights\")\n",
    "\n",
    "#getting the hidden layer for the model\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers().flatten()]\n",
    "\n",
    "#getting the class IDs' from the file coco.names for detecting the particular object which is car in this case\n",
    "with open(\"coco.names\", \"r\") as file:\n",
    "    class_list = [line.strip() for line in file.readlines()]\n",
    "car_label_index = class_list.index(\"car\")\n",
    "\n",
    "#getting the mask for the colours to be considered\n",
    "def filter_colors(frame):\n",
    "    #converting the image from RGB format to HSV for better control of colors\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    #here we are considering both white and yellow colors as the Lanes are usually of these 2 colors\n",
    "\n",
    "    #defining the yellow color range and mask\n",
    "    yellow_lower_range = np.array([20, 100, 100])\n",
    "    yellow_upper_range = np.array([30, 255, 255])\n",
    "    yellow_mask = cv2.inRange(hsv, yellow_lower_range, yellow_upper_range)\n",
    "\n",
    "    #defining the white color range and mask\n",
    "    white_lower_range = np.array([0, 0, 200])\n",
    "    white_upper_range = np.array([255, 50, 255])\n",
    "    white_mask = cv2.inRange(hsv, white_lower_range, white_upper_range)\n",
    "\n",
    "    #combining both the masks\n",
    "    combined_mask = cv2.bitwise_or(yellow_mask, white_mask)\n",
    "\n",
    "    # applying the mask to the orginal frame\n",
    "    filtered_frame = cv2.bitwise_and(frame, frame, mask=combined_mask)\n",
    "\n",
    "    #uncomment in order to view the intermediate filtered image\n",
    "    # cv2.imshow(\"filtered_frame\",filtered_frame)\n",
    "    return filtered_frame\n",
    "\n",
    "#extracting the edges of the lanes\n",
    "def edges(frame):\n",
    "    #converting RGB into LAB format to get the Luminescence \n",
    "    lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    # applying CLAHE to the luminescence part so as to enhance the contrast in a certain range of intensity\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "    enhanced_lab = cv2.merge((l, a, b))\n",
    "    enhanced_frame = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Color filtering to isolate white and yellow\n",
    "    frame = filter_colors(enhanced_frame)\n",
    "    #uncomment in order to display the yellow and white mask\n",
    "    # cv2.imshow(\"yellow and white mask\",frame)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #uncomment in order to display the gray image\n",
    "    # cv2.imshow(\"gray\",gray)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    #uncomment in order to display the blurred image\n",
    "    # cv2.imshow(\"blur\",blur)\n",
    "\n",
    "    #Using canny edge algorithm to detect the edges\n",
    "    edges = cv2.Canny(blur, 50, 150)\n",
    "    #uncomment in order to display the edges image\n",
    "    # cv2.imshow(\"edges\",edges)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "#defining the region of interest in order to focus only on the Roads.\n",
    "def ROI(edge_frame):\n",
    "    height, width = edge_frame.shape[:2]\n",
    "    #defining the region of interest's dimensions\n",
    "    vertices = np.array([[\n",
    "        (50, height),                    # bottom left\n",
    "        (width - 50, height),            # bottom right\n",
    "        (width // 2 + 100, height // 2), # top right\n",
    "        (width // 2 - 100, height // 2)  # top left\n",
    "    ]], dtype=np.int32)  \n",
    "\n",
    "    # creating a mask in the same region as that of the roi and applying on the frame to get the masked frame\n",
    "    mask = np.zeros_like(edge_frame)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked_edges = cv2.bitwise_and(edge_frame, mask)\n",
    "    #uncomment in order to get the masked edge image\n",
    "    # cv2.imshow(\"masked_edges\",masked_edges)\n",
    "    return masked_edges\n",
    "\n",
    "#getting the top view of the road\n",
    "def birds_view_func(masked_edges,source_points,destination_points):\n",
    "    height, width = masked_edges.shape[:2]\n",
    "    #transformation matrix \n",
    "    A = cv2.getPerspectiveTransform(source_points, destination_points)\n",
    "    top_view = cv2.warpPerspective(masked_edges, A, (width,height), cv2.INTER_LINEAR)\n",
    "    #uncomment in order to get the top view of lane\n",
    "    # cv2.imshow(\"bird's eye's view\",top_view)\n",
    "    return top_view\n",
    "\n",
    "#collecting the lane pixel points from the top view\n",
    "def lane_pixels(binary_top_view):\n",
    "    # collecting the histogram of the bottom half of the top view which is nearest to the car\n",
    "    histo = np.sum(binary_top_view[binary_top_view.shape[0] // 2:, :], axis=0)\n",
    "\n",
    "    # mid point of the histogram\n",
    "    midpoint = int(histo.shape[0] // 2)\n",
    "\n",
    "    # search window range and kernel size\n",
    "    margin = 100  \n",
    "    kernel_size = 50  \n",
    "\n",
    "    # convolving the kernel with the histogram\n",
    "    convo_window = np.ones(kernel_size)\n",
    "    convo_signal = np.convolve(histo, convo_window)\n",
    "\n",
    "    # redefining the peaks based on convolution signal\n",
    "    left_peak = np.argmax(convo_signal[:midpoint])\n",
    "    right_peak = np.argmax(convo_signal[midpoint:]) + midpoint\n",
    "\n",
    "    # finding the non zero pixels as they represent the lane pixel points\n",
    "    nonzero = binary_top_view.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "\n",
    "    # defining the pixels as left lane or right lane depending on the position within the margin\n",
    "    left_lane_idx = ((nonzero_x >= left_peak - margin) & (nonzero_x < left_peak + margin))\n",
    "    right_lane_idx = ((nonzero_x >= right_peak - margin) & (nonzero_x < right_peak + margin))\n",
    "\n",
    "    # extracting the lane pixel positions\n",
    "    left_x = nonzero_x[left_lane_idx]\n",
    "    left_y = nonzero_y[left_lane_idx]\n",
    "    right_x = nonzero_x[right_lane_idx]\n",
    "    right_y = nonzero_y[right_lane_idx]\n",
    "\n",
    "    return left_x, left_y, right_x, right_y\n",
    "\n",
    "#fitting the lane pixels with a 3 degree polynomial \n",
    "def fit_lane_pixels(top_view):\n",
    "    left_x, left_y, right_x, right_y = lane_pixels(top_view)\n",
    "\n",
    "    # getting the 3 degree polynomial for both the lanes\n",
    "    left_fit = np.polyfit(left_y, left_x, 3)\n",
    "    right_fit = np.polyfit(right_y, right_x, 3)\n",
    "\n",
    "    # getting the y coordinates\n",
    "    plot_y = np.linspace(0, top_view.shape[0] - 1, top_view.shape[0])\n",
    "\n",
    "    # getting the x coordinates using coeficients from the polynomial calculated above\n",
    "    left_fit_x = left_fit[0] * plot_y**3 + left_fit[1] * plot_y**2 + left_fit[2] * plot_y + left_fit[3]\n",
    "    right_fit_x = right_fit[0] * plot_y**3 + right_fit[1] * plot_y**2 + right_fit[2] * plot_y + right_fit[3]\n",
    "\n",
    "    return left_fit_x, right_fit_x, plot_y, left_fit, right_fit\n",
    "\n",
    "\n",
    "#calculating the radius of curvature(ROC) from the 3 degree polynomial \n",
    "def calculate_ROC(left_fit, right_fit, plot_y):\n",
    "    y_eval = np.max(plot_y)\n",
    "    y_in_m = 30 / 720   # meters per pixel in y dimension\n",
    "\n",
    "    # curvature formula (given in report)\n",
    "    left_ROC = ((1 + (3*left_fit[0]*y_eval**2*y_in_m + 2*left_fit[1]*y_eval*y_in_m + left_fit[2])**2)**1.5) / np.abs(6*left_fit[0]*y_eval*y_in_m + 2*left_fit[1])\n",
    "    right_ROC = ((1 + (3*right_fit[0]*y_eval**2*y_in_m + 2*right_fit[1]*y_eval*y_in_m + right_fit[2])**2)**1.5) /np.abs(6*right_fit[0]*y_eval*y_in_m + 2*right_fit[1])\n",
    "    avg_ROC = (left_ROC +right_ROC)/2 \n",
    "\n",
    "    return left_ROC, right_ROC, avg_ROC\n",
    "\n",
    "#predicting direction of steering\n",
    "def steering_direction(left_fit_x, right_fit_x, frame_width):\n",
    "    # getting the center of the road nearest to the car(bottom of the image)\n",
    "    lane_center = (left_fit_x[-1] + right_fit_x[-1]) / 2\n",
    "    # assuming vehicle's center is at the center of the frame as most of the cars have their dashcam fitted at the center\n",
    "    car_center = frame_width / 2  \n",
    "\n",
    "    # calculating the differnce between the lane center and the car center\n",
    "    diff = lane_center - car_center\n",
    "\n",
    "    # determining the direction of steering by setting a threshold of 50 pixels\n",
    "    if abs(diff) < 50:  \n",
    "        return \"Straight\"\n",
    "    elif diff > 0:\n",
    "        return \"Right\"\n",
    "    else:\n",
    "        return \"Left\"\n",
    "\n",
    "#plotting the lane boundaries on the frame   \n",
    "def display_lane(original_frame, top_view, left_fit_x, right_fit_x, plot_y, matrix_inv):\n",
    "    # creating a blank top view and a coloured top view \n",
    "    blank_top_view = np.zeros_like(top_view).astype(np.uint8)\n",
    "    color_top_view = np.dstack((blank_top_view, blank_top_view, blank_top_view))\n",
    "\n",
    "  \n",
    "   # defining points for left and right lane boundaries\n",
    "    points_left = np.array([[x, y] for x, y in zip(left_fit_x, plot_y)])\n",
    "    points_right = np.array([[x, y] for x, y in zip(right_fit_x, plot_y)])\n",
    "\n",
    "\n",
    "    #colouring the boundaries \n",
    "    cv2.polylines(color_top_view, np.int_([points_left]), isClosed=False, color=(255, 0, 255), thickness=50)\n",
    "    cv2.polylines(color_top_view, np.int_([points_right]), isClosed=False, color=(255, 0, 255), thickness=50)\n",
    "\n",
    "    # converting the color image back into the car's perspective using the inverse trasnformation matrix \n",
    "    org_frame_plot = cv2.warpPerspective(color_top_view, matrix_inv, (original_frame.shape[1], original_frame.shape[0]))\n",
    "    \n",
    "    # combining the lane boundaries with the original frame\n",
    "    final_lane = cv2.addWeighted(original_frame, 0.7, org_frame_plot, 1, 0)\n",
    "    return final_lane\n",
    "\n",
    "\n",
    "#applying all the major lane detecting processes on the input frame\n",
    "def process_frame(frame):\n",
    "    edge_frame = edges(frame)\n",
    "    masked_edges = ROI(edge_frame)\n",
    "    # source points and destnation points for converting the ROI into top view\n",
    "    source_points = np.float32([\n",
    "        [width // 2 - 75, height // 2 + 100],\n",
    "        [width // 2 + 75, height // 2 + 100],\n",
    "        [width - 150, height],\n",
    "        [150, height]\n",
    "    ])\n",
    "    destination_points = np.float32([\n",
    "        [100, 0],\n",
    "        [width - 100, 0],\n",
    "        [width - 100, height],\n",
    "        [100, height]\n",
    "    ])\n",
    "    top_view=birds_view_func(masked_edges,source_points,destination_points)\n",
    "    matrix_inv=cv2.getPerspectiveTransform(destination_points, source_points)\n",
    "    left_fit_x, right_fit_x, plot_y, left_fit, right_fit = fit_lane_pixels(top_view)\n",
    "    left_ROC, right_ROC, avg_ROC = calculate_ROC(left_fit, right_fit, plot_y)\n",
    "    steering = steering_direction(left_fit_x, right_fit_x, frame.shape[1])\n",
    "    #displaying all the results on the frame\n",
    "    cv2.putText(frame, f\"Left Curvature Radius: {left_ROC:.2f} m\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Right Curvature Radius: {right_ROC:.2f} m\", (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 200, 255), 2)\n",
    "    cv2.putText(frame, f\"Average Curvature Radius: {avg_ROC:.2f} m\", (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Steering: {steering}\", (50, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 127, 255), 2)\n",
    "    lane_image = display_lane(frame, top_view, left_fit_x, right_fit_x, plot_y, matrix_inv)\n",
    "    #uncomment in order to display lane_image\n",
    "    # cv2.imshow(\"lane_image\",lane_image)\n",
    "    return lane_image\n",
    "\n",
    "def car_detection(frame, prev_centers, distance_per_pixel):\n",
    "    height, width = frame.shape[:2]\n",
    "    #creating binary large objects for input to YOLO model\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), (0, 0, 0),True,False)\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # passing forward to the output layers to get the detections\n",
    "    detections = net.forward(output_layers)\n",
    "\n",
    "    # creating the bounding box variable to store the height, width and the center of the boxes,scores for storing the-\n",
    "    #-probabilities of different class IDs'.\n",
    "    boxes, scores = [], []\n",
    "    new_centers = {}\n",
    "\n",
    "    # iterating over detections\n",
    "    for detection_layer in detections:\n",
    "        for obj_data in detection_layer:\n",
    "            score = obj_data[4]\n",
    "            prob = obj_data[5:]\n",
    "            detected_class = np.argmax(prob)\n",
    "            #if the detected class is the car and its score is greater than 0.5 then we will consider it to be a car\n",
    "            if detected_class == car_label_index and score > 0.5:\n",
    "                bbox_center_x, bbox_center_y, bbox_width, bbox_height = (obj_data[:4] * [width, height, width, height]).astype(int)\n",
    "                top_left_x = int(bbox_center_x - bbox_width / 2)\n",
    "                top_left_y = int(bbox_center_y - bbox_height / 2)\n",
    "                boxes.append([top_left_x, top_left_y, bbox_width, bbox_height])\n",
    "                scores.append(float(prob[detected_class]))\n",
    "                new_centers[len(new_centers)] = (bbox_center_x, bbox_center_y)\n",
    "\n",
    "    #applying non maximum supression to discard the overlapping of multiple boxes\n",
    "    selected_indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=0.5, nms_threshold=0.4)\n",
    "    # flattening it for iterations\n",
    "    detected_car_ids = set()\n",
    "    #creating a thereshold of 2100 in order to be considered a near car\n",
    "    MIN_BBOX_AREA = 2100 #pixel^2\n",
    "    car_count = 0\n",
    "    close_car_count=0\n",
    "    #considering a particular car for calculating its relative speed and area \n",
    "    for idx in selected_indices:\n",
    "        box_x, box_y, box_w, box_h = boxes[idx]\n",
    "        bbox_area = box_w * box_h\n",
    "        \n",
    "        centroid_x, centroid_y = new_centers[idx]\n",
    "        detected_car_ids.add(idx)\n",
    "\n",
    "        if idx in prev_centers:\n",
    "            old_x, old_y = prev_centers[idx]\n",
    "            #calculating the distance between the successive frames of a particular car\n",
    "            pixel_shift = ((centroid_x - old_x) ** 2 + (centroid_y - old_y) ** 2) ** 0.5\n",
    "            meters_shift = pixel_shift * distance_per_pixel\n",
    "            speed_mps = meters_shift * fps\n",
    "            speed_kph = speed_mps * 3.6\n",
    "\n",
    "            # displaying the relative speed of the car calculate above\n",
    "            cv2.putText(frame, f\"Relative_Speed: {speed_kph:.4f} km/h\", (box_x, box_y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        else:\n",
    "            speed_kph=0\n",
    "        prev_centers[idx] = (centroid_x, centroid_y)\n",
    "        #segregating the car as close car or far car \n",
    "        if bbox_area>=MIN_BBOX_AREA:\n",
    "            close_car_count+=1\n",
    "            color = (0,0,255)\n",
    "        else:\n",
    "            color=(0,255,0)\n",
    "\n",
    "        #bounding the car with a rectangle\n",
    "        cv2.rectangle(frame, (box_x, box_y), (box_x + box_w, box_y + box_h), color, 2)\n",
    "    prev_centers = {i: prev_centers[i] for i in detected_car_ids}\n",
    "    car_count=len(prev_centers)\n",
    "    return traffic_density(frame,car_count,close_car_count)\n",
    "\n",
    "def traffic_density(frame,car_count,close_car_count):\n",
    "\n",
    "    if car_count < 4:\n",
    "        density_level = \"Low\"\n",
    "        density_color = (0, 255, 0)  # green for low traffic\n",
    "    elif 4 <= car_count < 7:\n",
    "        density_level = \"Medium\"\n",
    "        density_color = (0, 255, 255)  # yellow for medium traffic\n",
    "    else:\n",
    "        density_level = \"High\"\n",
    "        density_color = (0, 0, 255)  # red for high traffic\n",
    "\n",
    "    # displaying density info on the frame\n",
    "    cv2.putText(frame, f\"Proximity Count: {close_car_count}\", (50, 170), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "    cv2.putText(frame, f\"Traffic Density: {density_level}\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, density_color, 2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "#storing the centers of the car of the previous frame\n",
    "prev_centers = {}\n",
    "\n",
    "#this could be calibrated depending on the car as well as the camera\n",
    "#used,for a general case the range should be from 0.02-0.05 hence we assumed it to be 0.04.\n",
    "distance_per_pixel = 0.04\n",
    "\n",
    "# getting the input video\n",
    "input_video = cv2.VideoCapture('curved_lane1.mp4')\n",
    "\n",
    "# getting the video's FPS and dimensions\n",
    "fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# inititalising the ideowriter with the correct resolution\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "\n",
    "# output files\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, 20.0, (width, height)) \n",
    "if not out.isOpened() or not out.isOpened():\n",
    "    print(\"Error: VideoWriter not opened properly!\")\n",
    "    input_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "while input_video.isOpened():\n",
    "    ret, frame = input_video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # processing the frame\n",
    "    lane_image= process_frame(frame)\n",
    "\n",
    "    # detecting the cars\n",
    "    model_frame=car_detection(lane_image, prev_centers, distance_per_pixel)\n",
    "    out.write(model_frame)\n",
    "\n",
    "    # showing the output in real time while its saving \n",
    "    cv2.imshow('final_output', model_frame)\n",
    "    # cv2.imshow('final_output', lane_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# releasing everything when completed\n",
    "input_video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
